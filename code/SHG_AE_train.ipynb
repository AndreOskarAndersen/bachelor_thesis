{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd015b452054a1f37423623dc03587790452578e39807b086c75f037ab8f1c9c424",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import re\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "from sklearn.utils import shuffle\n",
    "from SHG import SHG\n",
    "from AE import AE\n",
    "from SHG_AE import SHG_AE\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images\n",
    "TRAIN_IMGS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/train/image/\"\n",
    "VAL_IMGS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/validation/image/\"\n",
    "\n",
    "# Ground truth heatmaps\n",
    "TRAIN_HEATMAPS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/train/heatmaps/\"\n",
    "VAL_HEATMAPS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/validation/heatmaps/\"\n",
    "\n",
    "# Model paths\n",
    "SHG_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/models/Mon_Apr_12_18-11-59_2021/epoch_31.pth\"\n",
    "AE_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data_min_loss/AE_models/model.pth\"\n",
    "\n",
    "# Previously trained model\n",
    "SAVED_MODEL_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/SHG_AE/models/Wed_May_26_10-42-05_2021/epoch_14.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "cur_model_path = None\n",
    "start_epoch = 0\n",
    "train_loss = np.array([])\n",
    "val_loss = np.array([])\n",
    "val_acc = np.array([])\n",
    "scheduler = None\n",
    "optimizer = None\n",
    "\n",
    "# Read the mean rgb if it has been calculated previously\n",
    "try:\n",
    "    average_rgb = np.loadtxt(\"./average_rgb.npy\")\n",
    "except:\n",
    "    average_rgb = get_mean_rgb(TRAIN_IMGS_PATH)\n",
    "    np.savetxt(\"./average_rgb.npy\", average_rgb)\n",
    "\n",
    "# Load device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Define model\n",
    "SHG_model = SHG(num_hourglasses = 1).to(device)\n",
    "AE_model = AE().to(device)\n",
    "\n",
    "# If we decide to use a saved model\n",
    "if SAVED_MODEL_PATH is not None:\n",
    "    model = SHG_AE(SHG_model, AE_model)\n",
    "    model.load_state_dict(torch.load(SAVED_MODEL_PATH)) # loads the model\n",
    "    start_epoch = int(re.findall(\"(?<=epoch_)(.*)(?=.pth)\", SAVED_MODEL_PATH)[0]) + 1 # finds the starting epoch\n",
    "    cur_model_path = re.findall(\"^(.*)(?=epoch)\", SAVED_MODEL_PATH)[0] # finds the directory of the saved model\n",
    "    train_loss = np.load(cur_model_path + \"loss.npy\") # loads the average training loss\n",
    "    val_loss = np.load(cur_model_path + \"val_loss.npy\") # loads the validation loss\n",
    "    scheduler = torch.load(cur_model_path + \"scheduler.pth\") # loads scheduler\n",
    "    val_acc = np.load(cur_model_path + \"val_acc.npy\") # loads validation accuracy\n",
    "    optimizer = torch.load(cur_model_path + \"optimizer.pth\")\n",
    "else:\n",
    "    SHG_model.load_state_dict(torch.load(SHG_PATH))\n",
    "    AE_model.load_state_dict(torch.load(AE_PATH))\n",
    "    model = SHG_AE(SHG_model, AE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cur_model_path is None): # if we do not use a saved model\n",
    "    cur_model_path = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/SHG_AE/models/\" + time.asctime().replace(\" \", \"_\").replace(\":\", \"-\") + \"/\"\n",
    "    os.mkdir(cur_model_path)\n",
    "    print(\"Created directory at\", cur_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X_path, y_path, average_rgb):\n",
    "        self.X_path = X_path\n",
    "        self.y_path = y_path\n",
    "        self.X_data = os.listdir(self.X_path)\n",
    "        self.average_rgb = average_rgb\n",
    "        self.norm = transforms.Normalize(mean = self.average_rgb, std = [1, 1, 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ID = self.X_data[i]\n",
    "        x = Image.open(self.X_path + ID)\n",
    "\n",
    "        y = []\n",
    "\n",
    "        for i in range(17):\n",
    "            y.append(torch.from_numpy(np.load(self.y_path + ID[:-4] + \"/\" + str(i) + \".npy\")))\n",
    "\n",
    "        x = TF.to_tensor(x)\n",
    "\n",
    "        if (x.shape[0] == 1): # If the image is gray-scale, cast it to rgb\n",
    "            x = torch.stack((x[0],) * 3)\n",
    "\n",
    "        x = self.norm(x) # Subtracts mean rgb\n",
    "\n",
    "        y = torch.stack(y)\n",
    "        return x, y\n",
    "\n",
    "train_data = dataset(TRAIN_IMGS_PATH, TRAIN_HEATMAPS_PATH, average_rgb)\n",
    "val_data = dataset(VAL_IMGS_PATH, VAL_HEATMAPS_PATH, average_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USING LR = 0.00025\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 2.5e-4 if scheduler is None else scheduler.state_dict()[\"_last_lr\"][0]\n",
    "print(\"USING LR = {}\".format(LEARNING_RATE))\n",
    "NUM_EPOCHS = 100\n",
    "MINI_BATCH_SIZE = 16\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if (scheduler is None):\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr = LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.2, patience=5, mode = \"max\", min_lr = 2.5e-4 * 0.2, verbose=True)\n",
    "    \n",
    "train_dataloader = DataLoader(train_data, batch_size = MINI_BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_data, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='EPOCH', max=85.0, style=ProgressStyle(description_width='…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d93e48121fd3463ba408c28ac4b0cb27"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH 15\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46a2ae36637c40fa963ecec00331d858"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Average train loss: 4.661612236999962e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=5064.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "653b0899deb44b86a2f99fa1d7a4786b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Validation loss: 5.189297742022947e-05\n",
      "     Validation accuracy: 0.46745471958654927\n",
      "EPOCH 16\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a27aa4003146445fbf9b7dda859011ca"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Average train loss: 4.661875305826178e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=5064.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acddd55c56164af882a169f2870291d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Validation loss: 5.1837396925505e-05\n",
      "     Validation accuracy: 0.46736544898701576\n",
      "EPOCH 17\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2384bbb038c14254a77dfa5f50e0b6e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Average train loss: 4.6618444932999996e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=5064.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2efd9c0c83b54cd5b10c9e479fa58a49"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Validation loss: 5.199140229099107e-05\n",
      "     Validation accuracy: 0.4665877396314565\n",
      "EPOCH 18\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff0ccf868c154e2f8179173239b21199"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Average train loss: 4.662128372814927e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=5064.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4908f5a4bdc4428e8cb04579e2c270ff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Validation loss: 5.192512528446322e-05\n",
      "     Validation accuracy: 0.4669706294458\n",
      "EPOCH 19\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dfa8ce071f2439abc8b7c2f40da7fc1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Average train loss: 4.661524405713542e-05\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='VALIDATION', max=5064.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "275a5c3f8339487687bd2fe2673dbca8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Validation loss: 5.191023439836838e-05\n",
      "     Validation accuracy: 0.46673377505505664\n",
      "EPOCH 20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='MINI BATCH', max=7753.0, style=ProgressStyle(description_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e93da67a51a40df991e52a5dd92cbeb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d5157eed6607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Store train loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Backpropegation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in tqdm(range(start_epoch, NUM_EPOCHS), desc = \"EPOCH\"):\n",
    "    model.train()\n",
    "    train_loss = np.append(train_loss, 0)\n",
    "    print(\"EPOCH {}\".format(epoch))\n",
    "    for x, y in tqdm(train_dataloader, leave = False, desc = \"MINI BATCH\", total = len(train_dataloader)):\n",
    "        x = x.to(device, dtype = torch.float)\n",
    "        y = y.to(device, dtype = torch.float)\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x, add_noise = False)\n",
    "\n",
    "        # Backpropegation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Computes loss\n",
    "        loss = criterion(predictions.to(device), y)\n",
    "\n",
    "        # Store train loss\n",
    "        train_loss[-1] += loss.item()\n",
    "\n",
    "        # Backpropegation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss[-1] /= len(train_dataloader)\n",
    "    \n",
    "    print(\"     Average train loss: {}\".format(train_loss[-1]))\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = np.append(val_loss, 0)\n",
    "        val_acc = np.append(val_acc, 0)\n",
    "        for x, y in tqdm(val_dataloader, leave = False, desc = \"VALIDATION\", total = len(val_dataloader)):\n",
    "            x = x.to(device, dtype = torch.float)\n",
    "            y = y.to(device, dtype = torch.float)\n",
    "\n",
    "            # Predict\n",
    "            predictions = model(x, add_noise = False)\n",
    "\n",
    "            # Loss\n",
    "            loss = criterion(predictions, y)\n",
    "\n",
    "            # Storing validation loss\n",
    "            val_loss[-1] += loss.item()\n",
    "\n",
    "            # Storing validation accuracy\n",
    "            val_acc[-1] += PCK(y.cpu(), predictions.cpu())\n",
    "\n",
    "        val_loss[-1] /= len(val_dataloader)\n",
    "        val_acc[-1] /= len(val_dataloader)\n",
    "\n",
    "    print(\"     Validation loss: {}\".format(val_loss[-1]))\n",
    "    print(\"     Validation accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "    # Saving model\n",
    "    torch.save(model.state_dict(), cur_model_path + \"/epoch_{}\".format(epoch) + \".pth\")\n",
    "\n",
    "    # Saving training loss\n",
    "    np.save(cur_model_path + \"loss.npy\", train_loss)\n",
    "\n",
    "    # Saving validation loss\n",
    "    np.save(cur_model_path + \"val_loss.npy\", val_loss)\n",
    "\n",
    "    # Saving validation acc\n",
    "    np.save(cur_model_path + \"val_acc.npy\", val_acc)\n",
    "\n",
    "    # Saving optimizer\n",
    "    torch.save(optimizer, cur_model_path + \"optimizer.pth\")\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step(val_acc[-1])\n",
    "    torch.save(scheduler, cur_model_path + \"scheduler.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}