{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bsc_project_prework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2226079f43ee4d02aae9bed04b504760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a46a3c2839145b297ac8f1a0889e04f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bf6ebb7d38054a35b83bdba8c40c3da4",
              "IPY_MODEL_7ad4311496b64c89b46cc9293a781c89"
            ]
          }
        },
        "0a46a3c2839145b297ac8f1a0889e04f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf6ebb7d38054a35b83bdba8c40c3da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5659015ba92643aaa5de8b9c3e201c48",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 64115,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 687,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6417e11e46642a1a39beb635988cf3f"
          }
        },
        "7ad4311496b64c89b46cc9293a781c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df0d463185254c0ab8b148604fcac278",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 687/64115 [07:27&lt;10:23:50,  1.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29dbd800d5024d33a14d52cf2315372d"
          }
        },
        "5659015ba92643aaa5de8b9c3e201c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6417e11e46642a1a39beb635988cf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df0d463185254c0ab8b148604fcac278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29dbd800d5024d33a14d52cf2315372d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR8ZmiEUiN8x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import skimage.io as io\n",
        "from pycocotools.coco import COCO # DOC: https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py\n",
        "import pylab\n",
        "from tqdm.notebook import tqdm\n",
        "import skimage\n",
        "import skimage.draw\n",
        "import skimage.transform\n",
        "import skimage.filters\n",
        "from sklearn.model_selection import train_test_split\n",
        "import h5py\n",
        "import wget\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4cR3tRxjXW"
      },
      "source": [
        "def draw_keypoints(I, keypoints, r = 0.75, g = 0.6, b = 0.2, radius = 2):\n",
        "  \"\"\"Draws keypoints on image\"\"\"\n",
        "  I_copy = np.copy(I)\n",
        "  x_val = keypoints[::3]\n",
        "  y_val = keypoints[1::3]\n",
        "  v_val = keypoints[2::3]\n",
        "\n",
        "  for x, y, v in zip(x_val, y_val, v_val):\n",
        "    if (v != 0):\n",
        "      rr, cc = skimage.draw.circle(y, x, radius)\n",
        "      I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  return I_copy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPpu3c-rTft9"
      },
      "source": [
        "def draw_bbox(I, bbox, r, g, b):\n",
        "  I_copy = np.copy(I)\n",
        "\n",
        "  x_min = np.ceil(bbox[0]).astype(\"int\")\n",
        "  x_max = np.floor(bbox[0] + bbox[2]).astype(\"int\")\n",
        "  y_min = np.ceil(bbox[1]).astype(\"int\")\n",
        "  y_max = np.floor(bbox[1] + bbox[3]).astype(\"int\")\n",
        "\n",
        "  rr, cc = skimage.draw.line(y_min, x_min, y_min, x_max)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.line(y_max, x_min, y_max, x_max)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.line(y_min, x_min, y_max, x_min)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.line(y_min, x_max, y_max, x_max)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  return I_copy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO-fd-sCYqDk"
      },
      "source": [
        "def draw_segmentation_extremes(I, segmentation, r, g, b, radius):\n",
        "  assert len(segmentation) == 1\n",
        "\n",
        "  I_copy = np.copy(I)\n",
        "  segmentation = np.array(segmentation[0]).reshape((-1, 2))\n",
        "  x_min, y_min = np.min(segmentation, axis = 0)[0], np.min(segmentation, axis = 0)[1]\n",
        "  x_max, y_max = np.max(segmentation, axis = 0)[0], np.max(segmentation, axis = 0)[1]\n",
        "\n",
        "  rr, cc = skimage.draw.circle(y_min, x_min, radius)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.circle(y_max, x_min, radius)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.circle(y_min, x_max, radius)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  rr, cc = skimage.draw.circle(y_max, x_max, radius)\n",
        "  I_copy[rr - 1, cc - 1] = [r, g, b]\n",
        "\n",
        "  return I_copy"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT8iGC94t9ov"
      },
      "source": [
        "def crop_image(I, anns, margin_size):\n",
        "  \"\"\"Crops images\"\"\"\n",
        "  res_images = []\n",
        "  res_keypoints = []\n",
        "\n",
        "  # For each person in the image\n",
        "  for person in range(len(anns)):  \n",
        "\n",
        "    I_copy = np.copy(I)\n",
        "\n",
        "    keypoints = np.array(anns[person][\"keypoints\"])\n",
        "    num_keypoints = len(keypoints)\n",
        "    bbox = anns[person][\"bbox\"]\n",
        "    x_val = np.array(keypoints[::3]) - 1 # COCO is not 0-indexed\n",
        "    y_val = np.array(keypoints[1::3]) - 1 # COCO is not 0-indexed\n",
        "    v_val = keypoints[2::3]\n",
        "\n",
        "    # If the current person is not annotated with keypoints\n",
        "    if (int(np.sum(v_val)) == 0):\n",
        "      continue\n",
        "\n",
        "    # Finding edges of bounding box\n",
        "    x_min = np.floor(bbox[0]).astype(\"int\")\n",
        "    y_min = np.floor(bbox[1]).astype(\"int\")\n",
        "    x_max = np.ceil(bbox[0] + bbox[2]).astype(\"int\")\n",
        "    y_max = np.ceil(bbox[1] + bbox[3]).astype(\"int\")\n",
        "\n",
        "    # If bounding box does not contain every keypoint, expand it so it does\n",
        "    keypoints = keypoints.reshape((-1, 3))\n",
        "    filtered_keypoints = keypoints[keypoints[:, -1] != 0] # keypoints where v != 0\n",
        "    min_keypoints = np.min(filtered_keypoints, axis = 0)\n",
        "    max_keypoints = np.max(filtered_keypoints, axis = 0)\n",
        "    x_min_kp = min_keypoints[0]\n",
        "    x_max_kp = max_keypoints[0]\n",
        "    y_min_kp = min_keypoints[1]\n",
        "    y_max_kp = max_keypoints[1]\n",
        "    x_min = min(x_min, x_min_kp)\n",
        "    y_min = min(y_min, y_min_kp)\n",
        "    x_max = max(x_max, x_max_kp)\n",
        "    y_max = max(y_max, y_max_kp)\n",
        "\n",
        "    # If it is not possible for the image to be centered wrt the x-axis\n",
        "    if (x_min_kp + (x_max_kp - x_min_kp)/2 - (y_max_kp - y_min_kp)/2 < 0 or x_min_kp + (x_max_kp - x_min_kp)/2 + (y_max_kp - y_min_kp)/2 > I.shape[1]):\n",
        "      continue\n",
        "\n",
        "     # Makes the image have squared aspect ratio\n",
        "    if (x_max - x_min > y_max - y_min):\n",
        "      additional = 1/2 * ((x_max - x_min) - (y_max - y_min))\n",
        "      y_max += np.ceil(additional).astype(\"int\")\n",
        "      y_min -= np.floor(additional).astype(\"int\")\n",
        "    elif (y_max - y_min > x_max - x_min):\n",
        "      additional = 1/2 * ((y_max - y_min) - (x_max - x_min))\n",
        "      x_max += np.ceil(additional).astype(\"int\")\n",
        "      x_min -= np.floor(additional).astype(\"int\")\n",
        "\n",
        "    # Centers the bounding box around all of the keypoints of the person\n",
        "    old_x_min = x_min\n",
        "    old_x_max = x_max\n",
        "    center = [x_min_kp + (x_max_kp - x_min_kp)/2, y_min_kp + (y_max_kp - y_min_kp)/2]\n",
        "    x_kp_center_coor = center[0]\n",
        "    curr_x_center_coor = x_min + (x_max - x_min)/2\n",
        "    curr_y_center_coor = y_min + (y_max - y_min)/2\n",
        "    new_x_min = x_min + np.floor(x_kp_center_coor - curr_x_center_coor).astype(\"int\")\n",
        "    new_x_max = x_max + np.floor(x_kp_center_coor - curr_x_center_coor).astype(\"int\")\n",
        "    x_min = new_x_min\n",
        "    x_max = new_x_max\n",
        "\n",
        "    # Resizes the bbox\n",
        "    y_dist = y_max_kp - y_min_kp\n",
        "    x_dist = x_max_kp - x_min_kp\n",
        "    side_length = max(y_dist, x_dist) * (1 + margin_size)\n",
        "\n",
        "    if (side_length != 0):\n",
        "      x_side_diff = (x_max - x_min) - side_length\n",
        "      x_min += int(x_side_diff//2) \n",
        "      x_max -= int(x_side_diff//2)\n",
        "\n",
        "    # If the bbox with the margins does not fit in the image, shrink the bbox\n",
        "    if (x_min < 0):\n",
        "      x_max += -1 * (x_min)\n",
        "      y_max += -1 * (x_min)\n",
        "      y_min += x_min\n",
        "      x_min = 0\n",
        "    elif (x_max > I.shape[1]):\n",
        "      diff = x_max - I.shape[1]\n",
        "      x_max = I.shape[1]\n",
        "      x_min += diff\n",
        "      y_min += diff\n",
        "      y_max -= diff\n",
        "    \n",
        "    y_side_diff = (y_max - y_min) - side_length\n",
        "    if (y_side_diff != y_max - y_min):\n",
        "      y_min += int(y_side_diff//2)\n",
        "      y_max -= int(y_side_diff//2)\n",
        "\n",
        "    if (side_length < x_max_kp - x_min_kp or side_length < y_max_kp - y_min_kp): # if the bbox cannot fit the keypoints, discard this person\n",
        "      continue\n",
        "\n",
        "    # Moving the bbox up or down untill it fits all of the keypoints. If this is not possible, discard the image\n",
        "    y_kp_center_coor = center[1]\n",
        "    new_y_min = y_min + np.floor(y_kp_center_coor - curr_y_center_coor).astype(\"int\")\n",
        "    new_y_max = y_max + np.floor(y_kp_center_coor - curr_y_center_coor).astype(\"int\")\n",
        "    y_min = new_y_min\n",
        "    y_max = new_y_max\n",
        "\n",
        "    if (y_min < 0):\n",
        "      y_max += -1 * (y_min)\n",
        "      y_min = 0\n",
        "    elif (y_max > I.shape[0]):\n",
        "      y_min -= (y_max - I.shape[0])\n",
        "      y_max = I.shape[0]\n",
        "\n",
        "    I_cropped = I[y_min : y_max, x_min : x_max]\n",
        "\n",
        "    # Moving keypoints\n",
        "    x_val = np.array(x_val) - x_min\n",
        "    y_val = np.array(y_val) - y_min\n",
        "      \n",
        "    # Combining the keypoints into one array again\n",
        "    temp_keypoints = []\n",
        "    for t in zip(x_val, y_val, v_val):\n",
        "      for i in t:\n",
        "        temp_keypoints.append(i)\n",
        "\n",
        "    # Casting to np.arrays\n",
        "    I_cropped = np.array(I_cropped)\n",
        "    temp_keypoints = np.array(temp_keypoints)\n",
        "\n",
        "    # Appending the cropped image and the new keypoints to the results\n",
        "    res_images.append(I_cropped)\n",
        "    res_keypoints.append(temp_keypoints)\n",
        "\n",
        "  return res_images, res_keypoints"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7PJu9_6dWxk"
      },
      "source": [
        "def resize_img(I, keypoints, wanted_width, wanted_height):\n",
        "  \"\"\"Resizes image img and keypoints keypoints to have size wanted_height x wanted_width\"\"\"\n",
        "  I_resized = skimage.transform.resize(I, (wanted_width, wanted_height))\n",
        "\n",
        "  # Extracting keypoints coordinates\n",
        "  x_val = np.array(keypoints[::3]) * wanted_width//I.shape[1]\n",
        "  y_val = np.array(keypoints[1::3]) * wanted_height//I.shape[0]\n",
        "  v_val = np.array(keypoints[2::3])\n",
        "\n",
        "  # Combining the keypoints into one array again\n",
        "  keypoints_resize = []\n",
        "  for t in zip(x_val, y_val, v_val):\n",
        "    for i in t:\n",
        "      keypoints_resize.append(i)\n",
        "\n",
        "  assert I_resized.shape[0] == wanted_height and I_resized.shape[1] == wanted_width\n",
        "\n",
        "  return I_resized, keypoints_resize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7od_eqyj5fI"
      },
      "source": [
        "def prepare_image(I, anns, wanted_width, wanted_height, margin_size):\n",
        "  \"\"\"Crops and resizes a single image containing people\"\"\"\n",
        "\n",
        "  res_img, res_kp = [], []\n",
        "  cropped_images, cropped_keypoints = crop_image(I, anns, margin_size)\n",
        "\n",
        "  for image, keypoints in zip(cropped_images, cropped_keypoints):\n",
        "    resized_img, resized_kp = resize_img(image, keypoints,  wanted_width, wanted_height)\n",
        "    res_img.append(resized_img)\n",
        "    res_kp.append(resized_kp)\n",
        "\n",
        "  return res_img, np.array(res_kp)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VbGdTuGWG9a"
      },
      "source": [
        "def prepare_output(img_shape, wanted_width, wanted_height, keypoints):\r\n",
        "  \"\"\"Creates the 17 (or len(keypoints)/3) heatmaps corresponding to each keypoint of a single image with size wanted_height x wanted_width\"\"\"\r\n",
        "\r\n",
        "  # Finds boundingbox\r\n",
        "  x_val = keypoints[::3]\r\n",
        "  y_val = keypoints[1::3]\r\n",
        "  v_val = keypoints[2::3]\r\n",
        "\r\n",
        "  # The 17 results are stored here\r\n",
        "  res_arr = []\r\n",
        "\r\n",
        "  for x, y, v in zip(x_val, y_val, v_val):\r\n",
        "    x, y, v = int(x), int(y), int(v)\r\n",
        "    res = np.zeros((img_shape[0], img_shape[1]))\r\n",
        "    res[y - 1, x - 1] = 1\r\n",
        "\r\n",
        "    res = skimage.transform.resize(res, (wanted_height, wanted_width))\r\n",
        "    if (v == 1):\r\n",
        "      res = skimage.filters.gaussian(res, sigma = 1)\r\n",
        "    elif (v == 2):\r\n",
        "      res = skimage.filters.gaussian(res, sigma = 0.5)\r\n",
        "\r\n",
        "    res_arr.append(res)\r\n",
        "\r\n",
        "  return res_arr\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GibHLK7TSt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "2226079f43ee4d02aae9bed04b504760",
            "0a46a3c2839145b297ac8f1a0889e04f",
            "bf6ebb7d38054a35b83bdba8c40c3da4",
            "7ad4311496b64c89b46cc9293a781c89",
            "5659015ba92643aaa5de8b9c3e201c48",
            "f6417e11e46642a1a39beb635988cf3f",
            "df0d463185254c0ab8b148604fcac278",
            "29dbd800d5024d33a14d52cf2315372d"
          ]
        },
        "outputId": "dc975eb2-afcc-4ddf-fb99-e346db8dc372"
      },
      "source": [
        "\"\"\"Saving training/testing images\"\"\"\n",
        "\n",
        "annFile_instances = \"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/annotations/instances_train2017.json\"\n",
        "coco_instances = COCO(annFile_instances)\n",
        "\n",
        "catIds = coco_instances.getCatIds(catNms = ['person']) # Gets category ids with a person in it\n",
        "imgIds = coco_instances.getImgIds(catIds=catIds) # Gets all images with a person in it\n",
        "\n",
        "annFile_kp = \"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/annotations/person_keypoints_train2017.json\"\n",
        "coco_kps = COCO(annFile_kp) \n",
        "\n",
        "wanted_width, wanted_height = 256, 256\n",
        "margin_size = 0.1\n",
        "\n",
        "prep_anns = {}\n",
        "average_rgb = []\n",
        "\n",
        "for imgId in tqdm(imgIds):\n",
        "  img_info = coco_instances.loadImgs(imgId)[0]\n",
        "  annIds = coco_kps.getAnnIds(imgIds = img_info[\"id\"], catIds = catIds)\n",
        "  anns = coco_kps.loadAnns(annIds)\n",
        "  img = io.imread(img_info['coco_url'])\n",
        "  prepared_imgs, prepared_anns = prepare_image(img, anns, wanted_width, wanted_height, margin_size) # Prepares the image\n",
        "\n",
        "  for i, (prep_img, prep_ann) in enumerate(zip(prepared_imgs, prepared_anns)):\n",
        "    path_input = \"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/training_images/input/{}_{}.png\".format(img_info[\"id\"], i)\n",
        "    io.imsave(path_input, (prep_img * 255).astype(np.uint8)) # Saves the prepared image\n",
        "    prep_anns[\"{}_{}\".format(img_info[\"id\"], i)] = prep_ann\n",
        "\n",
        "    if (prep_img.reshape((prep_img.shape[0], prep_img.shape[1], -1)).shape[2] == 3):\n",
        "      average_rgb.append(prep_img.reshape(-1, 3))\n",
        "    elif (prep_img.reshape((prep_img.shape[0], prep_img.shape[1], -1)).shape[2]== 1):\n",
        "      average_rgb.append(np.stack((prep_img,)*3, axis = -1).reshape((-1, 3)))\n",
        "    else:\n",
        "      raise Exception(\"ELSE\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(prep_anns)\n",
        "df.to_csv(\"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/training_images/output.txt\", index = False)\n",
        "\n",
        "average_rgb = np.mean(np.array(average_rgb_arr).reshape((-1, 3)), axis = 0) # THIS CAUSES CRASH. MAYBE DUE TO THE UNNECESSARY RESHAPE?\n",
        "np.save(\"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/training_images/output/average_rgb.npy\", average_rgb)\n",
        "f = h5py.File(\"C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/training_images/output/average_rgb.h5\", \"w\")\n",
        "f.create_dataset(\"default\", data = average_rgb, dtype = average_rgb.dtype)\n",
        "f.close()\n",
        "\n",
        "!zip -r /content/data/training_images/input.zip /content/data/training_images/input"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=17.47s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=7.98s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "HBox(children=(FloatProgress(value=0.0, max=64115.0), HTML(value='')))",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a946e9e7cff4d76bb62c9ab2e11439e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: C:/Users/André/Onedrive 2/OneDrive/Skrivebord/bachelor_thesis/code/data/training_images/input/393418_1.png is a low contrast image\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-824783b31588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[0mannIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco_kps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAnnIds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0manns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco_kps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadAnns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannIds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coco_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m   \u001b[0mprepared_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprepared_anns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwanted_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Prepares the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mplugin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tifffile'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\io\\util.py\u001b[0m in \u001b[0;36mfile_or_url_context\u001b[1;34m(resource_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;31m# f must be closed before yielding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-DQacM_zZCQ"
      },
      "source": [
        "shuf -n 5064 -e /content/data/training_images/input/* | xargs -i mv {} /content/data/training_images/input/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}