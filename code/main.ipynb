{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "15b452054a1f37423623dc03587790452578e39807b086c75f037ab8f1c9c424"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.filters\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import cv2\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.functional import relu\n",
    "from torchsummary import summary\n",
    "from sklearn.utils import shuffle\n",
    "from SHG import SHG\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS_PATH = \"D:/bsc_data/train/outputs.txt\"\n",
    "#TEST_LABELS_PATH = \"D:/bsc_data/test/outputs.txt\"\n",
    "VAL_LABELS_PATH = \"D:/bsc_data/validation/test.txt\"\n",
    "\n",
    "HEADER = [\"ID\"]\n",
    "for i in range(17):\n",
    "    HEADER.append(\"x{}\".format(i))\n",
    "    HEADER.append(\"y{}\".format(i))\n",
    "    HEADER.append(\"v{}\".format(i))\n",
    "\n",
    "train_labels = pd.read_csv(TRAIN_LABELS_PATH, delimiter = \",\", names = HEADER)\n",
    "#test_labels = pd.read_csv(TEST_LABELS_PATH, delimiter = \",\", names = HEADER)\n",
    "val_labels = pd.read_csv(VAL_LABELS_PATH, delimiter = \",\", names = HEADER)\n",
    "print(val_labels.shape)\n",
    "\n",
    "TRAIN_IMGS_PATH = \"D:/bsc_data/train/image/\"\n",
    "#TEST_IMGS_PATH = \"D:/bsc_data/test/image/\"\n",
    "VAL_IMGS_PATH = \"D:/bsc_data/validation/image/\"\n",
    "\n",
    "train_imgs = os.listdir(TRAIN_IMGS_PATH)\n",
    "#test_imgs = os.listdir(TEST_IMGS_PATH)\n",
    "val_imgs = os.listdir(VAL_IMGS_PATH)\n",
    "\n",
    "train_labels, train_imgs = shuffle(train_labels, train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2.5e-4\n",
    "NUM_EPOCHS = 100\n",
    "MINI_BATCH_SIZE = 16\n",
    "MINI_BATCHES = np.array_split(train_imgs, len(train_imgs)/MINI_BATCH_SIZE)\n",
    "SAVED_MODEL_PATH = \"D:/bsc_data/models/Wed_Mar_17_16-05-12_2021/epoch_0.pth\"\n",
    "cur_model_path = None\n",
    "start_epoch = 0\n",
    "average_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "try:\n",
    "    average_rgb = np.loadtxt(\"./average_rgb.npy\")\n",
    "except:\n",
    "    average_rgb = get_mean_rgb(TRAIN_IMGS_PATH, train_imgs)\n",
    "    np.savetxt(\"./average_rgb.npy\", average_rgb)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SHG(num_hourglasses=1).to(device)\n",
    "\n",
    "if SAVED_MODEL_PATH is not None:\n",
    "    model.load_state_dict(torch.load(SAVED_MODEL_PATH))\n",
    "    start_epoch = int(re.findall(\"(?<=epoch_)(.*)(?=.pth)\", SAVED_MODEL_PATH)[0]) + 1\n",
    "    cur_model_path = re.findall(\"^(.*)(?=epoch)\", SAVED_MODEL_PATH)[0]\n",
    "    average_loss = np.loadtxt(cur_model_path + \"/loss.npy\", delimiter = \",\")\n",
    "    \n",
    "    try:\n",
    "        validation_loss = np.loadtxt(cur_model_path + \"/val_loss.npy\", delimiter = \",\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cur_model_path is None):\n",
    "    cur_model_path = \"D:/bsc_data/models/\" + time.asctime().replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "    os.mkdir(cur_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in tqdm(range(start_epoch, NUM_EPOCHS), desc = \"EPOCH\"):\n",
    "    model.train()\n",
    "    average_loss = np.append(average_loss, 0)\n",
    "    for i, mini_batch in tqdm(enumerate(MINI_BATCHES[:5]), leave = False, desc = \"MINI BATCH\", total = len(MINI_BATCHES[:5])):\n",
    "        # Creating data\n",
    "        heatmaps = []\n",
    "        imgs = []\n",
    "        for img_name in mini_batch:\n",
    "            heatmaps.append(create_heatmaps(train_labels.loc[train_labels[\"ID\"] == img_name[:-4]].to_numpy()))\n",
    "            img = plt.imread(TRAIN_IMGS_PATH + img_name)\n",
    "\n",
    "            if (len(img.shape) == 2):\n",
    "                img = grey_to_rgb(img)\n",
    "\n",
    "            img -= average_rgb\n",
    "\n",
    "            imgs.append(img)\n",
    "\n",
    "        heatmaps = torch.FloatTensor(heatmaps).to(device)\n",
    "\n",
    "        imgs = (torch.from_numpy(np.array(imgs)).permute(0, 3, 1, 2)).to(device)\n",
    "\n",
    "        # Prediction\n",
    "        predictions = model(imgs)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(predictions.to(device), heatmaps)\n",
    "\n",
    "        average_loss[-1] += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i % 1000 == 0):\n",
    "            print(loss)\n",
    "    \n",
    "    average_loss[-1] /= len(MINI_BATCHES)\n",
    "\n",
    "    # Saving model\n",
    "    torch.save(model.state_dict(), cur_model_path + \"/epoch_{}\".format(epoch) + \".pth\")\n",
    "\n",
    "    # Saving loss\n",
    "    np.savetxt(cur_model_path + \"/loss.npy\", average_loss)\n",
    "\n",
    "    print(\"average loss of epoch {}: {}\".format(epoch, average_loss[-1]))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    average_val_loss = 0\n",
    "    for val_img in tqdm(val_imgs, leave = False, desc = \"Valdiation\", total = len(val_imgs)):\n",
    "        heatmaps = create_heatmaps(val_labels.loc[val_labels[\"ID\"] == val_img[:-4]].to_numpy())\n",
    "        img = plt.imread(VAL_IMGS_PATH + val_img)\n",
    "\n",
    "        if (len(img.shape) == 2):\n",
    "            img = grey_to_rgb(img)\n",
    "\n",
    "        img -= average_rgb\n",
    "\n",
    "        heatmaps = torch.FloatTensor(heatmaps)\n",
    "        heatmaps = heatmaps.reshape((1, heatmaps.shape[0], heatmaps.shape[1], heatmaps.shape[2])).to(device)\n",
    "        img = torch.from_numpy(np.array(img)).reshape((1, 3, img.shape[0], img.shape[1]))\n",
    "        img = img.to(device)\n",
    "        average_val_loss += criterion(model(img), heatmaps).item()\n",
    "    average_val_loss /= len(val_imgs)\n",
    "    validation_loss.append(average_val_loss)\n",
    "    print(\"Validation loss at epoch {}: {}\".format(epoch, average_val_loss))\n",
    "    np.savetxt(cur_model_path + \"/val_loss.npy\", validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.imread(VAL_IMGS_PATH + val_imgs[0])\n",
    "\n",
    "gt_kp = val_labels.loc[val_labels[\"ID\"] == val_imgs[0][:-4]].to_numpy()[0][1:]\n",
    "\n",
    "model.eval()\n",
    "x_tensor = torch.from_numpy(x).permute((2, 0, 1)).to(device)\n",
    "x_tensor = x_tensor.reshape((1, x_tensor.shape[0], x_tensor.shape[1], x_tensor.shape[2]))\n",
    "pred = model(x_tensor).cpu().data.numpy()[0]\n",
    "print(pred.shape)\n",
    "print(np.mean(pred))\n",
    "\n",
    "img, pred_keypoints = draw_predicitions_and_gt(x, gt_kp, pred)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ]
}