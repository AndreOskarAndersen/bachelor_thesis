{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd015b452054a1f37423623dc03587790452578e39807b086c75f037ab8f1c9c424",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.manifold import TSNE\n",
    "from SHG import SHG\n",
    "from utils import *\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.base import clone\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from AE import CONV_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PATHS \"\"\"\n",
    "\n",
    "# MODELS\n",
    "AE_MODEL_ALL_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/models/all/model.pth\"\n",
    "AE_MODEL_FULL_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/models/full/model.pth\"\n",
    "\n",
    "# DATA\n",
    "ALL_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/train_all/\"\n",
    "FULL_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/train_full_skeleton/\"\n",
    "\n",
    "# SAVING PATH\n",
    "ALL_SAVING_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/AE_latent_spaces/all/\"\n",
    "FULL_SAVING_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/AE_latent_spaces/full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DATASET AND DATALOADER \"\"\"\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, PATH):\n",
    "        self.FULL_PATH = PATH\n",
    "        self.listdir = os.listdir(self.FULL_PATH)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listdir)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ID = self.listdir[i]\n",
    "        path = self.FULL_PATH + ID\n",
    "        data = np.load(path)\n",
    "        return data, ID\n",
    "\n",
    "ALL_DATASET = dataset(ALL_PATH)\n",
    "ALL_DATALOADER = DataLoader(ALL_DATASET)\n",
    "\n",
    "FULL_DATASET = dataset(FULL_PATH)\n",
    "FULL_DATALOADER = DataLoader(FULL_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CONV_AE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\"\"\" Configurations \"\"\"\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MODELS\n",
    "AE_ALL = CONV_AE().to(device)\n",
    "AE_ALL.load_state_dict(torch.load(AE_MODEL_ALL_PATH))\n",
    "AE_ALL.eval()\n",
    "\n",
    "AE_FULL = CONV_AE().to(device)\n",
    "AE_FULL.load_state_dict(torch.load(AE_MODEL_FULL_PATH))\n",
    "AE_FULL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=124040.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5abcb5d9f40a467ab75d38090a4e85f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SAVING PREDICTIONS OF AE_ALL \"\"\"\n",
    "with torch.no_grad():\n",
    "    for x, ID in tqdm(ALL_DATALOADER, leave = False):\n",
    "        ID = ID[0]\n",
    "        x = x.to(device, dtype = torch.float)\n",
    "        y = AE_ALL.encode(x).cpu().data.numpy()\n",
    "        np.save(ALL_SAVING_PATH + ID, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=7017.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d46489557a94020a487049b154ec384"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "\"\"\" SAVING PREDICTIONS OF AE_FULL \"\"\"\n",
    "with torch.no_grad():\n",
    "    for x, ID in tqdm(FULL_DATALOADER, leave = False):\n",
    "        ID = ID[0]\n",
    "        x = x.to(device, dtype = torch.float)\n",
    "        y = AE_FULL.encode(x).cpu().data.numpy()\n",
    "        np.save(FULL_SAVING_PATH + ID, y)"
   ]
  }
 ]
}