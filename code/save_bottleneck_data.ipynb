{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd015b452054a1f37423623dc03587790452578e39807b086c75f037ab8f1c9c424",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.manifold import TSNE\n",
    "from SHG import SHG\n",
    "from utils import *\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.base import clone\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(train_dataloader, device, model, NUM_DATAPOINTS, save = False):\n",
    "    \"\"\" Finds NUM_DATAPOINTS from train_dataloader of fully annotated images \"\"\"\n",
    "    bottleneck_arr = []\n",
    "    gt_heatmaps = []\n",
    "    IDs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, id_ in tqdm(train_dataloader):\n",
    "            x = x.to(device, dtype = torch.float)\n",
    "\n",
    "            if (0 not in np.array(turn_featuremaps_to_keypoints(y)).reshape((-1, 3))[:, -1]):\n",
    "                _, bottleneck = model(x)\n",
    "\n",
    "                bottleneck_arr.append(bottleneck[2].cpu().data.numpy().flatten())\n",
    "                gt_heatmaps.append(turn_featuremaps_to_keypoints(y))\n",
    "                IDs.append(id_)\n",
    "\n",
    "                if (len(bottleneck_arr) == NUM_DATAPOINTS):\n",
    "                    break\n",
    "\n",
    "    bottleneck_arr = np.array(bottleneck_arr).reshape((len(bottleneck_arr), -1))\n",
    "    gt_heatmaps = np.array(gt_heatmaps).reshape((len(gt_heatmaps), -1))\n",
    "    \n",
    "    if (save):\n",
    "        dump(IDs, SAVING_PATH + str(NUM_DATAPOINTS) + \"/\" + \"IDs.joblib\") # Saving the IDs of the images worked on\n",
    "\n",
    "    return bottleneck_arr, gt_heatmaps, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PATHS \"\"\"\n",
    "# Input images\n",
    "TRAIN_IMGS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/train/image/\"\n",
    "\n",
    "# Ground truth heatmaps\n",
    "TRAIN_HEATMAPS_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/train/heatmaps/\"\n",
    "\n",
    "# Path for model\n",
    "MODEL_DIR = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/models/Mon_Apr_12_18-11-59_2021/epoch_46.pth\"\n",
    "\n",
    "# Path for mean rgb\n",
    "average_rgb = np.loadtxt(\"./average_rgb.npy\")\n",
    "\n",
    "# Saving path\n",
    "SAVING_PATH = \"C:/Users/André/OneDrive 2/OneDrive/Skrivebord/bsc_data/latent_space_data/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DATASET AND DATALOADER \"\"\"\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, X_path, y_path, average_rgb):\n",
    "        self.X_path = X_path\n",
    "        self.y_path = y_path\n",
    "        self.X_data = os.listdir(self.X_path)\n",
    "        self.average_rgb = average_rgb\n",
    "        self.norm = transforms.Normalize(mean = self.average_rgb, std = [1, 1, 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ID = self.X_data[i]\n",
    "        x = Image.open(self.X_path + ID)\n",
    "\n",
    "        y = []\n",
    "\n",
    "        for i in range(17):\n",
    "            y.append(torch.from_numpy(np.load(self.y_path + ID[:-4] + \"/\" + str(i) + \".npy\")))\n",
    "\n",
    "        x = TF.to_tensor(x)\n",
    "\n",
    "        if (x.shape[0] == 1): # If the image is gray-scale, cast it to rgb\n",
    "            x = torch.stack((x[0],) * 3)\n",
    "\n",
    "        x = self.norm(x) # Subtracts mean rgb\n",
    "\n",
    "        y = torch.stack(y)\n",
    "        return x, y, ID\n",
    "\n",
    "train_data = dataset(TRAIN_IMGS_PATH, TRAIN_HEATMAPS_PATH, average_rgb)\n",
    "train_dataloader = DataLoader(train_data, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LOADING MODEL \"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SHG(num_hourglasses = 1, use_skip_connections = False).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_DIR))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" Save each fully annotated image, from the bottleneck \"\"\"\n",
    " \n",
    " with torch.no_grad():\n",
    "    for x, y, id_ in tqdm(train_dataloader):\n",
    "        x = x.to(device, dtype = torch.float)\n",
    "\n",
    "        if (0 not in np.array(turn_featuremaps_to_keypoints(y)).reshape((-1, 3))[:, -1]):\n",
    "            _, bottleneck = model(x)\n",
    "\n",
    "            bottleneck = bottleneck[-1][0].cpu().data.numpy()\n",
    "            np.save(SAVING_PATH + id_[0][:-4], bottleneck)"
   ]
  }
 ]
}