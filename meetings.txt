1. meeting
* https://github.com/tensorflow/tfjs-models/tree/master/posenet
* https://cocodataset.org/#home
* 2D articulated human pose estimation og hvad lærer modellen? ("Hvad lærer modellen" skal være lidt ekstra - altså, krøllen på halen)
* Brug scholar.google.com til at kigge frem i tiden
* Survey er papirer der sammenligner metoder
* Autoencoder med clustering og pca på midter lag (tror det hed bottleneck) kan bruges til at finde ud af hvad et et CNN lærer
* https://www.dropbox.com/sh/xden54w9z4imfld/AACVStkQSm-NV4EVIV65jwBBa?dl=0

* Kig på stacked hourglass
* Læs om autoencoder
* Skriv projektbeskrivelse (1. problem/motivation, 2. Dataset, 3. Projektplan/tidsplan, 4. projektspecifikke læringsmål)
* Læs Newell og Papendreou papers
* Kig på Michelles master thesis om pose estimation (tror det var noget med ballet)

Forberedelse til møde 2:
* Anvendelse af google collab (eller lignende)?
* Hvilken model skal bruges? Er ret glad for stacked hour glass
* Hvad skal jeg gøre med beskrivelsen af datasættet, projektets forbindelse til datalogi osv...
* Holder man ferie?
* Gode kilder på preprocessing af billeder som data
* Hvilket sprog samt bibliotek?

2. meeting:
* Behøver ikke være verdens bedste model - det er vigtigere den kan skildes ad
* Måske både giv billede og skelet som input/output til autoencoder
* Stacked hour glass: plus er concat, box er convolution (+ max pooling)
* EVERYTHING YOU NEED TO LEARN ABOUT DEEP LEARNING FOR COMPUTER VISION (læs frem til autoencover (og måske inklusiv))
* scikit image (vær opmærksom på bgr istedet for rgb)
* Kig på andre modellen inden Stacked hour glass inden jeg låser mig fast
* Skriv noget ned om COCO når jeg begynder at kigge på det, som så skal skrives ind i rapporten.
* Skriv noget ned om de artikler jeg har læst om, som så smides ind i indledningen. Skriv den sammenhængende valg af metode. "Der findes de her artikler ..., jeg har valgt at tage udgangspunkt i denne her artikel fordi...". Måske endda skriv dette allerede nu

Forberedelse til møde 3:
* For at gøre brug af SHG (eller en anden single-human model) skal der kun være én person i hvert billede - i COCO er der flere, hvordan gør jeg dette? Skal personen være i midten af billedet? Jeg har croppet billedet, så billedet tilpasses efter keypointsne
* Keypoints'ne består af 3 punkter: x, y, v, hvor v viser om keypointet er visible. Skal v også bruges til at træne modelen?
* Flere af de artikler jeg har læst flipper, roterer, rescaler, tilfører støj til deres billeder, burder jeg også gøre det?
* Hver kropsdel er ikke en enkel pixel i virkeligheden, men det er det i datasættet. Skal jeg tilføje en radius rundt om den "rigtige" pixel, som så fungerer som et "korrekt område"?
* Hvis en artikel har fundet en måde der bygger videre på SHG og forbedrer det, er det noget jeg burde overveje at gøre?
    * Ved godt det ikke behøver være verdens bedste model, men kunne det ikke være fedt at vise i mit projekt, at jeg har læst videre på den oprindelige idet. "Newell gør det på denne her måde, men det har vist sig at være bedere hvis man gør det på denne her måde..." - eller måske kan dette måske bruges når jeg skal forbedre min model efter XAI?
* "Related work"-afsnit i projekt?
* Hvor meget inspiration må jeg tage fra Camillas rapport?

Forberedelse til møde 4:
* Kontrakt er blevet godkendt
* Når jeg laver referencer til en artikle e.l., skal jeg så skrive hele navnet og alle navne eller et "Newell et. al" fint?
* Skal jeg referere til COCO hjemmesiden eller artiklen fra google scholar?
* Skal jeg skrive sidetal/sektion ned, når jeg laver referencer til artiker?
* Når jeg skriver at jeg bruger eksempelvis pytorch, skal jeg så referere til det? eller må jeg antage at læserne kender til det?
* Hvorfor sjove farver i rapport?
* Kan jeg skrive, at heatmaps fungerer som en "sandsynlighed" for hvor et led er?
* Skal jeg skrive hvordan man får dataen? eller er det fint at skrive, at jeg bruger COCO og så må læserne selv finde ud af hvordan man får det?
* Jeg udvider pt hver bounding box med 50 px. Burde jeg gøre, så det istedet afhænger af størrelsen af bounding boxen?
* Bedre måde at gemme preprocessed billeder på end png?
(https://stackoverflow.com/a/41425878/12905157)
* Skæv fordeling af validation og testing? (testing er ca. 5 gange så stort som validation)
* Hvilke activation function ville være passende?
* Hvad menes der med "After reaching the output resolution of the network, two consecutive rounds of 1x1 convolutions are applied to produce the final network predictions."
* For hver branch er der kun én convolution eller har de bare kun tegnet én?

Forberedelse til møde 5:
* Jeg havde tænkt mig, at gøre forskel på heatmaps hvor et led er synligt og hvor ledet ikke er synligt, men det gør Newell ikke - skal jeg så også droppe det?
* SHG, fig 4: betyder 128x1x1 virkelig 128 convolutions af størrelse 1x1?
* Newell bruger 8 hourglasses, men Camilla bruger kun 2?
* Er "convolution", "kernel" og "filter" det samme? - Det lille gitter med tal.
* De skriver "Filters greater than 3x3 are never used" - dette gælder både for maxpooling og convolutions?
* Er én "feature" én pixel?
* Er i tvivl om kernel size ved maxpooling, da de ikke skriver dette. Istedet skriver de bare, at netværket når sin laveste resolution ved 4x4 pixels
* Sker prediction ved den blå boks eller ved addition? Er den blå boks en convolution (det ligner det ved camillas - de skriver også 
* Skal blokkende i Fig. 4 højre forstås som convolutions eller som residual modules?
* Skal der altid en activation efter en convolution?
* Residuals downsampler også en lille smule - er det meningen eller skal jeg justere dem, så de ikke gør?
* Nogle komponenter passer ikke sammen med den information der er givet. Kan det passe at noget information (padding, stride, kernel size) ikke er givet så man skal selv justere på dette indtil at komponenterne passer sammen?
* Er det meningen, at hvert hourglass kun skal spytte 17 heatmaps ud? eller er det meningen af det først er til sidst at de 17 heatmaps laves
* Maxpooling på kernel_size = 60 tager meget lang tid
* Hvorfor har output egentlig en size på 64x64?
* I tvivl om hvor activation functions skal være. Har bare fulgt Camillas
* Hvordan ved jeg hvilke heatmaps der svarer til de rigtige? (ved beregning as loss)
* Ikke helt sikker på hvor lossen skal anvendes efter den sidste hourglass
* Med 2 hourglasses har jeg cirka 24 mio parametrer - lyder det ikke lidt voldsomt?
* Laver jeg backpropagation rigtigt? (samler loss for hvert hourglass i en liste, laver forward prop, kører så over listen og laver backprop., på hver loss)