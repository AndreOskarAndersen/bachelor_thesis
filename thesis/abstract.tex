\documentclass[./main.tex]{subfiles}

\begin{document}
\section{Abstract}
In this thesis we implement and train the Stacked hourglass developed by Newell \textit{et al.} \cite{Newell}. The network is trained, validation and tested on the Microsoft 2017 COCO dataset \cite{COCO_article}. This is followed by an interpretation of the developed model. In the interpretation we first off verify Newell \textit{et al.} \cite{Newell} and Olsen's \cite{Camilla} claim, that the skip-connections are used for recreating details that are lost during the encoder-phase. Then, we analyse the structure of the latent space. In correlation to this we conclude, that the model has learned the difference between people standing up and sitting down, learned the difference between moving and stationary people, as well as learned the difference between almost fully-annotated people and not fully-annotated people. During the interpretation we further conclude, that there are some redundancy and missplaced training samples in the latent space of the model. Finally, we use the obtained knowledge about the model to improve the performance and reduce the redundancy of the model. This is done by modifying the architecture of the model to include an autoencoder. 

\end{document}